# Contributing to LLM OS

This project is built with AI, by AI, for everyone. Every contribution — whether generated by Claude Code, Cursor, Copilot, or hand-written — is welcome.

## Core Values — Every Contribution Must Respect These

Before writing a single line, internalize these. PRs that violate them will be rejected.

**1. Protect the user first.** No telemetry. No tracking. No data exfiltration. No phoning home. Generated apps are sandboxed. Capabilities require explicit user approval. When in doubt, deny access. User privacy is non-negotiable.

**2. Empower the user.** Never add artificial limitations. The OS exists to serve the user, not to gatekeep what they can run. If a user wants to generate and run an app, let them — unless it harms others.

**3. Take a piece, leave a piece.** You benefit from this project? Give something back. Even a bug report counts. Code that is contributed must not damage or disrupt the core idea of this OS.

**4. Nothing is perfect.** Ship working code, improve later. Don't over-engineer. Don't block progress waiting for perfection. But never violate the core intent.

---

## Contributing with Claude Code (VS Code)

**This is the easiest way to contribute.** The repo includes a `CLAUDE.md` that automatically gives Claude Code full project context, architecture, and values.

### Quick Start

```bash
# 1. Fork and clone
gh repo fork DayZAnder/llm-os --clone
cd llm-os

# 2. Open in VS Code with Claude Code
code .

# 3. Tell Claude Code what to build (examples below)

# 4. Test your changes
node src/server.js

# 5. Submit a PR
gh pr create
```

When you open this repo in VS Code with Claude Code, it reads `CLAUDE.md` and understands:
- The architecture and how components connect
- The core values and security requirements
- What code exists and what's still needed
- The coding style (vanilla JS, no frameworks, dark theme)

### Prompts to Paste into Claude Code

Pick one, paste it into Claude Code, and let it work. Each prompt is self-contained and includes the values context.

---

### Prompt 1: WASM Sandbox (replace iframes)

```
Read the existing iframe sandbox in src/shell/sandbox.js and src/sdk/sdk.js.

Build a WebAssembly-based sandbox to replace (or sit alongside) the iframe approach.
Use Wasmtime or Extism as the WASM runtime.

Core value reminder: Protect the user first. The WASM sandbox must be MORE restrictive
than iframes, not less. No filesystem access, no network access, no capabilities
unless explicitly granted by the kernel with user approval.

Requirements:
- A WasmSandbox class with the same interface as the iframe SandboxManager
- launch(appId, code, capabilities, title) → runs app in WASM sandbox
- kill(appId) → terminates sandbox
- postMessage-equivalent communication channel between kernel and WASM app
- Capability enforcement: WASM app cannot call any host function without a valid capability
- Memory limits per sandbox (configurable, default 64MB)
- CPU time limits (kill after 30 seconds of continuous execution)

Put it in src/kernel/wasm-sandbox/. Include tests.
Make it work standalone — don't break the existing iframe sandbox.
```

---

### Prompt 2: Cryptographic Capability Tokens

```
Read the existing simple capability system in src/kernel/capabilities.js.

Replace the in-memory whitelist with cryptographic capability tokens.

Core value reminder: Protect the user first. Tokens must be unforgeable.
A generated app must NEVER be able to escalate its own privileges.
All capability grants require explicit user approval.

Requirements:
- HMAC-SHA256 signed tokens using Web Crypto API (SubtleCrypto) — no npm crypto libs
- Token contains: appId, capability type, scope constraints, expiry, nonce
- Kernel generates a random secret on startup (regenerated each session)
- verifyToken() is constant-time to prevent timing attacks
- Revocation list for tokens that should be invalidated early
- Backward compatible: existing capability checks still work

Update src/kernel/capabilities.js in place. Add tests that verify:
- Valid tokens are accepted
- Tampered tokens are rejected
- Expired tokens are rejected
- Revoked tokens are rejected
- Apps cannot forge tokens without the kernel secret
```

---

### ~~Prompt 3: App Registry~~ — DONE

> Implemented in `src/kernel/registry/store.js`. Content-addressed with SHA-256, trigram fuzzy search, community sync from GitHub. See the Browse Apps button in the shell.

**Next step:** Improve the registry — add ratings, install counts, featured apps, or a web-based registry browser.

---

### ~~Prompt 4: Bootable Linux Image~~ — DONE

> Implemented in `build/`. Alpine Linux VM with Docker + Node.js, outputs QCOW2 (Proxmox) and VHDX (Hyper-V). Download from [Releases](https://github.com/DayZAnder/llm-os/releases).

**Next step:** Add kiosk browser mode (Chromium auto-launching into the shell), OVA for VirtualBox, or CI builds via GitHub Actions.

---

### Prompt 3: Persistent Storage Layer

```
Read the existing in-memory storage in src/sdk/sdk.js (LLMOS.storage API).

Replace the ephemeral in-memory storage with persistent storage that survives
app restarts and OS reboots.

Core value reminder: Protect the user first. Storage is per-app, isolated by
appId. One app must NEVER be able to read another app's data. All data stays
local — never synced to any external service.

Requirements:
- Use the filesystem (JSON files in data/apps/<appId>/) — no database dependency
- LLMOS.storage.get/set/delete work the same but persist to disk
- Storage quota per app (default 5MB, configurable)
- Storage usage visible in capability approval dialog
- Export/import user data (all apps or per-app)
- Backward compatible: existing apps work without changes

Update src/server.js with storage API endpoints.
Update src/sdk/sdk.js to use the new persistent backend.
Add tests.
```

---

### Prompt 4: CI Pipeline (GitHub Actions)

```
Set up GitHub Actions to automatically build and test LLM OS on every push/PR.

Core value reminder: Nothing is perfect — but CI catches regressions before
they reach users. Every PR should pass before merge.

Requirements:
- Run all tests (node --test tests/*.test.js) on push and PR
- Run the values-check workflow (already exists, wire it in)
- Build the VM image on tagged releases (v*)
- Upload QCOW2 and VHDX as release assets automatically
- Build matrix: Node.js 22 on Ubuntu
- Cache node_modules between runs
- Badge in README showing build status

Put workflows in .github/workflows/. The VM build needs Docker (privileged).
```

---

### Prompt 5: Improve the Shell UI

```
Read src/shell/index.html — the current desktop UI.

Improve it while keeping the core architecture (vanilla JS, no frameworks).

Core value reminder: Empower the user. The UI should be fast, responsive,
and get out of the user's way. The prompt bar is the primary interaction.

Requirements:
- Add drag-and-drop window resizing (currently only tiling)
- Add window minimize/maximize (currently only close)
- Add a "recently generated" sidebar showing last 10 apps from the log
- Add keyboard shortcut: Ctrl+Space to focus the prompt bar
- Add keyboard shortcut: Ctrl+W to close the focused app
- Add a settings panel (accessible via gear icon) for:
  - Ollama URL
  - API keys (masked input)
  - Default capabilities to auto-approve
- Improve the capability approval dialog:
  - Show a brief explanation of each capability
  - Remember user preferences ("always allow timer:basic")
- Keep the dark color scheme: bg #0d0d1a, accent #6c63ff
- Keep it vanilla JS — no React, no Vue

Edit src/shell/index.html in place. Test by running node src/server.js.
```

---

### Prompt 6: Security Hardening

```
Read all files in src/kernel/ and src/sdk/sdk.js.

Audit the security of the current prototype and fix any issues you find.

Core value reminder: Protect the user first. This is the most important
contribution you can make. A sandbox escape or prompt injection bypass
means a generated app could harm the user's system.

Look for and fix:
1. Sandbox escape vectors: Can an iframe app access the parent frame?
   Can it make network requests? Can it read cookies or localStorage
   from the host?
2. Prompt injection bypasses: Can a user craft a prompt that makes the
   LLM ignore its system prompt? Can it leak the system prompt?
3. Static analysis gaps: What malicious patterns does analyzer.js miss?
   Add detection rules for anything you find.
4. Capability bypass: Can an app call storage/network without having
   the capability approved?
5. postMessage security: Is the message origin validated? Can a third-party
   page inject messages?

For each issue found:
- Fix it in the code
- Add a test case that verifies the fix
- Add a comment explaining the attack vector

Put new tests in tests/security/. Create the directory if needed.
```

---

### Prompt 7: Rust Microkernel Research Spike

```
This is a research task, not production code.

Create a proof-of-concept Rust no_std microkernel that boots via UEFI
and renders "LLM OS" to a framebuffer.

Core value reminder: Nothing is perfect. This is an experiment. It won't
be complete. The goal is to prove we CAN boot without Linux and show the
path forward for Phase 4.

Requirements:
- Rust #![no_std] #![no_main]
- UEFI boot via uefi-rs crate
- Get the framebuffer from UEFI GOP (Graphics Output Protocol)
- Render "LLM OS v0.0.1" to the screen using a bitmap font
- Set up a basic heap allocator
- Bonus: initialize a simple serial console for debug output
- Bonus: basic keyboard input via UEFI SimpleTextInput

Put it in experimental/microkernel/. Include a README with build
instructions (cargo build --target x86_64-unknown-uefi).
This should boot in QEMU with OVMF firmware.
```

---

## Low-Token Contributions (Quick Wins)

Have limited AI tokens? These focused tasks are small, self-contained, and valuable. Each takes 5–15 minutes.

### Security Test Vectors

```
Read tests/security/injection-vectors.json and tests/security/analyzer-vectors.json.
Add 5 NEW test vectors to each file. Focus on edge cases the existing vectors miss:
- Unicode homoglyph attacks (Cyrillic а instead of Latin a)
- Multi-line comment tricks (/* */ wrapping malicious code)
- CSS @import data exfiltration
- WebRTC-based fingerprinting
Follow the existing JSON format exactly. Each vector needs: input, shouldFlag (boolean), category, description.
```

### Example App

```
Read the examples/ directory. Look at calculator.html and todo.html for the pattern.
Build ONE new example app (pick one: unit converter, color picker, markdown previewer, habit tracker).
Use the same style: self-contained HTML, dark theme (#1a1a2e bg, #6c63ff accent),
capabilities comment on line 1, LLMOS.storage for persistence if needed.
Keep it under 120 lines.
```

### Analyzer Rule

```
Read src/kernel/analyzer.js. Understand the rule format.
Add ONE new detection rule for a pattern the analyzer currently misses.
Ideas: WebRTC access, SharedArrayBuffer, Blob URL creation, CSS expression(),
document.write, innerHTML with user input, importScripts in workers.
Add a matching test vector to tests/security/analyzer-vectors.json.
```

### Documentation Fix

```
Read README.md and CONTRIBUTING.md. Find anything unclear, outdated, or missing.
Fix it. Examples: broken links, unclear setup steps, missing prerequisites,
typos, better explanations for non-native English speakers.
```

---

## Contributing Without Claude Code

### Using any AI assistant (ChatGPT, Gemini, Copilot, etc.)

Copy one of the prompts above and prepend this context block:

```
PROJECT CONTEXT:
I'm contributing to LLM OS (https://github.com/DayZAnder/llm-os), an operating
system where every app is generated by AI from natural language prompts.

The project has 4 non-negotiable core values:
1. PROTECT THE USER FIRST — privacy, no telemetry, sandbox everything, user approves all capabilities
2. EMPOWER THE USER — no artificial limits, let them run what they want
3. TAKE A PIECE, LEAVE A PIECE — open source, contribute back, don't break the core
4. NOTHING IS PERFECT — ship working code, iterate, never violate core intent

Tech: Node.js, vanilla JS (no React/Vue), ES modules, dark theme (#0d0d1a).
Security: iframe sandboxes, capability-based access, static analysis, prompt injection defense.

Now, here's my task:
```

Then paste the specific task prompt.

### Contributing without AI

Human contributions are equally valuable:

- **Security audits** — Try to break the sandbox. Try prompt injection. File issues.
- **Threat modeling** — What attack vectors are we missing?
- **Design mockups** — UI/UX for the shell, capability dialogs, app launcher
- **Performance profiling** — Measure generation → sandbox → launch latency
- **Documentation** — Explain the architecture, write tutorials
- **Translations** — Localize the shell UI

## Code Guidelines

- Vanilla JavaScript (ES modules, `type: "module"` in package.json)
- No classes where functions suffice
- No frameworks (React, Vue, Angular) in the shell or kernel
- Zero runtime dependencies unless absolutely necessary (currently: none)
- Tests welcome (vitest preferred, but any test runner works)
- Dark color scheme: `--bg-primary: #0d0d1a`, `--accent: #6c63ff`
- Every security decision should err on the side of denying access

## PR Checklist

Before submitting, verify:

- [ ] Does not add telemetry, analytics, or tracking of any kind
- [ ] Does not weaken sandbox isolation
- [ ] Does not bypass capability checks
- [ ] Does not add unnecessary dependencies
- [ ] Works standalone (can be tested independently)
- [ ] Follows the dark minimal visual style
- [ ] Includes tests for security-critical code
- [ ] References the relevant GitHub issue

## Communication

- **Issues:** Bug reports, feature proposals, security concerns
- **Discussions:** Architecture debates, open questions, ideas
- **PRs:** Code contributions (reference the issue number)
- **Security vulnerabilities:** File a private security advisory on GitHub

---

*This OS is built with AI, by AI, for humans. The next operating system won't ship apps — it will generate them. If that future interests you, open the repo in VS Code, let Claude Code read the CLAUDE.md, and start building.*
