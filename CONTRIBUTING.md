# Contributing to LLM OS

This project is built with AI, by AI, for everyone. Every contribution — whether generated by Claude Code, Cursor, Copilot, or hand-written — is welcome.

## Core Values — Every Contribution Must Respect These

Before writing a single line, internalize these. PRs that violate them will be rejected.

**1. Protect the user first.** No telemetry. No tracking. No data exfiltration. No phoning home. Generated apps are sandboxed. Capabilities require explicit user approval. When in doubt, deny access. User privacy is non-negotiable.

**2. Empower the user.** Never add artificial limitations. The OS exists to serve the user, not to gatekeep what they can run. If a user wants to generate and run an app, let them — unless it harms others.

**3. Take a piece, leave a piece.** You benefit from this project? Give something back. Even a bug report counts. Code that is contributed must not damage or disrupt the core idea of this OS.

**4. Nothing is perfect.** Ship working code, improve later. Don't over-engineer. Don't block progress waiting for perfection. But never violate the core intent.

---

## Contributing with Claude Code (VS Code)

**This is the easiest way to contribute.** The repo includes a `CLAUDE.md` that automatically gives Claude Code full project context, architecture, and values.

### Quick Start

```bash
# 1. Fork and clone
gh repo fork DayZAnder/llm-os --clone
cd llm-os

# 2. Open in VS Code with Claude Code
code .

# 3. Tell Claude Code what to build (examples below)

# 4. Test your changes
node src/server.js

# 5. Submit a PR
gh pr create
```

When you open this repo in VS Code with Claude Code, it reads `CLAUDE.md` and understands:
- The architecture and how components connect
- The core values and security requirements
- What code exists and what's still needed
- The coding style (vanilla JS, no frameworks, dark theme)

### Prompts to Paste into Claude Code

Pick one, paste it into Claude Code, and let it work. Each prompt is self-contained and includes the values context.

---

### ~~Prompt 1: WASM Sandbox~~ — DONE

> Implemented in `src/kernel/wasm-sandbox/`. Node.js built-in WebAssembly + worker_threads, zero dependencies. Capability-gated host functions, bounded memory (64MB max), CPU timeouts (30s default), SharedArrayBuffer + Atomics IPC. 27 tests in `tests/wasm-sandbox.test.js`.

**Next step:** Add storage host call integration test (WASM module that reads/writes via `storage:local` capability), or add network host calls (`network:http` capability).

---

### Prompt 2: Cryptographic Capability Tokens

```
Read the existing simple capability system in src/kernel/capabilities.js.

Replace the in-memory whitelist with cryptographic capability tokens.

Core value reminder: Protect the user first. Tokens must be unforgeable.
A generated app must NEVER be able to escalate its own privileges.
All capability grants require explicit user approval.

Requirements:
- HMAC-SHA256 signed tokens using Web Crypto API (SubtleCrypto) — no npm crypto libs
- Token contains: appId, capability type, scope constraints, expiry, nonce
- Kernel generates a random secret on startup (regenerated each session)
- verifyToken() is constant-time to prevent timing attacks
- Revocation list for tokens that should be invalidated early
- Backward compatible: existing capability checks still work

Update src/kernel/capabilities.js in place. Add tests that verify:
- Valid tokens are accepted
- Tampered tokens are rejected
- Expired tokens are rejected
- Revoked tokens are rejected
- Apps cannot forge tokens without the kernel secret
```

---

### ~~Prompt 3: App Registry~~ — DONE

> Implemented in `src/kernel/registry/store.js`. Content-addressed with SHA-256, trigram fuzzy search, community sync from GitHub. See the Browse Apps button in the shell.

**Next step:** Improve the registry — add ratings, install counts, featured apps, or a web-based registry browser.

---

### ~~Prompt 4: Bootable Linux Image~~ — DONE

> Implemented in `build/`. Alpine Linux VM with Docker + Node.js, outputs QCOW2 (Proxmox) and VHDX (Hyper-V). Download from [Releases](https://github.com/DayZAnder/llm-os/releases).

**Next step:** Add kiosk browser mode (Chromium auto-launching into the shell), OVA for VirtualBox, or CI builds via GitHub Actions.

---

### ~~Prompt 3: Persistent Storage Layer~~ — DONE

> Implemented in `src/kernel/storage.js`. Per-app JSON files in `data/apps/<appId>/`, 5MB quota, path traversal protection, debounced writes, export/import. 43 tests in `tests/storage.test.js`.

**Next step:** Add storage usage display in the capability approval dialog, or add storage migration/versioning.

---

### Prompt 4: CI Pipeline (GitHub Actions)

```
Set up GitHub Actions to automatically build and test LLM OS on every push/PR.

Core value reminder: Nothing is perfect — but CI catches regressions before
they reach users. Every PR should pass before merge.

Requirements:
- Run all tests (node --test tests/*.test.js) on push and PR
- Run the values-check workflow (already exists, wire it in)
- Build the VM image on tagged releases (v*)
- Upload QCOW2 and VHDX as release assets automatically
- Build matrix: Node.js 22 on Ubuntu
- Cache node_modules between runs
- Badge in README showing build status

Put workflows in .github/workflows/. The VM build needs Docker (privileged).
```

---

### Prompt 5: Improve the Shell UI

```
Read src/shell/index.html — the current desktop UI.

Improve it while keeping the core architecture (vanilla JS, no frameworks).

Core value reminder: Empower the user. The UI should be fast, responsive,
and get out of the user's way. The prompt bar is the primary interaction.

Requirements:
- Add drag-and-drop window resizing (currently only tiling)
- Add window minimize/maximize (currently only close)
- Add a "recently generated" sidebar showing last 10 apps from the log
- Add keyboard shortcut: Ctrl+Space to focus the prompt bar
- Add keyboard shortcut: Ctrl+W to close the focused app
- Add a settings panel (accessible via gear icon) for:
  - Ollama URL
  - API keys (masked input)
  - Default capabilities to auto-approve
- Improve the capability approval dialog:
  - Show a brief explanation of each capability
  - Remember user preferences ("always allow timer:basic")
- Keep the dark color scheme: bg #0d0d1a, accent #6c63ff
- Keep it vanilla JS — no React, no Vue

Edit src/shell/index.html in place. Test by running node src/server.js.
```

---

### Prompt 6: Security Hardening

```
Read all files in src/kernel/ and src/sdk/sdk.js.

Audit the security of the current prototype and fix any issues you find.

Core value reminder: Protect the user first. This is the most important
contribution you can make. A sandbox escape or prompt injection bypass
means a generated app could harm the user's system.

Look for and fix:
1. Sandbox escape vectors: Can an iframe app access the parent frame?
   Can it make network requests? Can it read cookies or localStorage
   from the host?
2. Prompt injection bypasses: Can a user craft a prompt that makes the
   LLM ignore its system prompt? Can it leak the system prompt?
3. Static analysis gaps: What malicious patterns does analyzer.js miss?
   Add detection rules for anything you find.
4. Capability bypass: Can an app call storage/network without having
   the capability approved?
5. postMessage security: Is the message origin validated? Can a third-party
   page inject messages?

For each issue found:
- Fix it in the code
- Add a test case that verifies the fix
- Add a comment explaining the attack vector

Put new tests in tests/security/. Create the directory if needed.
```

---

### Prompt 7: Rust Microkernel Research Spike

```
This is a research task, not production code.

Create a proof-of-concept Rust no_std microkernel that boots via UEFI
and renders "LLM OS" to a framebuffer.

Core value reminder: Nothing is perfect. This is an experiment. It won't
be complete. The goal is to prove we CAN boot without Linux and show the
path forward for Phase 4.

Requirements:
- Rust #![no_std] #![no_main]
- UEFI boot via uefi-rs crate
- Get the framebuffer from UEFI GOP (Graphics Output Protocol)
- Render "LLM OS v0.0.1" to the screen using a bitmap font
- Set up a basic heap allocator
- Bonus: initialize a simple serial console for debug output
- Bonus: basic keyboard input via UEFI SimpleTextInput

Put it in experimental/microkernel/. Include a README with build
instructions (cargo build --target x86_64-unknown-uefi).
This should boot in QEMU with OVMF firmware.
```

---

## Quality Control Prompts — Help Verify What's Been Built

LLM OS is built by AI agents. That means QC is just as important as code generation — we need agents reviewing agents' work. These prompts are designed for exactly that: paste one into your AI tool and let it audit, flag issues, and suggest improvements.

**Every QC finding is a valid PR.** Found a false positive in the analyzer? File it. Found a test gap? Add the test. Found generated code that smells wrong? Fix it.

### QC Prompt 1: Analyzer False Positive / False Negative Audit

```
Read src/kernel/analyzer.js — this is the static security analyzer for LLM-generated code.
Read tests/security/analyzer-vectors.json — existing test vectors.

Your job: find rules that are too strict (false positives) or too loose (false negatives).

For each of the ~35 regex rules in the analyzer:
1. Construct a BENIGN code snippet that the rule would incorrectly flag (false positive)
2. Construct a MALICIOUS code snippet that evades the rule (false negative)
3. Rate the rule's precision: HIGH (few false positives), MEDIUM, LOW (noisy)

Output a JSON array of findings:
[{
  "rule": "RULE_NAME",
  "type": "false_positive" | "false_negative",
  "code": "the code snippet",
  "explanation": "why this is a problem",
  "suggested_fix": "improved regex or new rule"
}]

Focus on real-world patterns, not contrived edge cases. Think about what an LLM would
actually generate vs. what an attacker would actually try. Add any new test vectors to
tests/security/analyzer-vectors.json.
```

### QC Prompt 2: Generated App Security Review

```
Read src/kernel/analyzer.js to understand what the static analyzer checks for.
Read src/sdk/sdk.js to understand the SDK API available to generated apps.
Read the examples/ directory to see reference apps.

Now read each app in the registry/ directory (if any) or examples/ directory.
For EACH app, produce a security assessment:

1. SANDBOX ESCAPE: Does it try to access parent/top/window.parent? Any postMessage to '*'?
2. DATA EXFILTRATION: Does it load external resources (images, scripts, CSS)?
   Does it use fetch/XHR without network capability?
3. CAPABILITY ABUSE: Does it use SDK functions beyond its declared capabilities?
4. CODE QUALITY: Is the HTML well-formed? Does JS have obvious bugs?
5. USER EXPERIENCE: Does it match the dark theme (#0d0d1a bg, #6c63ff accent)?
   Is it actually useful for what the prompt asked?

Rate each app: PASS (ship it), WARN (needs minor fixes), FAIL (regenerate or reject).

For WARN/FAIL apps, provide specific code fixes. Submit fixes as a PR.
```

### QC Prompt 3: Test Coverage Gap Analysis

```
Read ALL test files in tests/ directory. Read ALL source files in src/kernel/ and src/sdk/.

For each source module, list:
1. Functions/methods that HAVE test coverage
2. Functions/methods that have NO test coverage
3. Edge cases that existing tests miss (empty input, large input, concurrent calls, error paths)

Produce a coverage report:

| Module | Functions Tested | Functions Untested | Missing Edge Cases |
|--------|-----------------|-------------------|-------------------|

Then pick the 3 most critical gaps (prioritize security-related code) and write the
missing tests. Follow the existing test pattern: custom assert functions, no test framework,
console output with checkmarks.

Add new tests to the appropriate existing test file. Run the full suite:
node tests/analyzer.test.js && node tests/storage.test.js && node tests/registry.test.js && node tests/scheduler.test.js && node tests/gateway.test.js && node tests/wasm-sandbox.test.js
```

### QC Prompt 4: SDK Isolation Verification

```
Read src/sdk/sdk.js — this runs INSIDE untrusted iframe sandboxes.
Read src/shell/sandbox.js — this manages sandboxes from the trusted side.
Read src/kernel/capabilities.js — this controls what apps can do.

Your job: try to break the isolation. For each SDK function:

1. Can a malicious app call it without the required capability?
2. Can a malicious app craft a postMessage that the kernel would trust?
3. Can a malicious app access other apps' storage?
4. Can a malicious app escalate its capabilities at runtime?
5. Can a malicious app DoS the kernel (infinite messages, huge payloads)?

For each attack vector you find:
- Write a proof-of-concept code snippet
- Verify whether the analyzer catches it
- Suggest a fix (code patch or new analyzer rule)

Output findings as a markdown table:
| Attack | Possible? | Analyzer Catches? | Fix |
```

### QC Prompt 5: WASM Sandbox Security Audit

```
Read src/kernel/wasm-sandbox/index.js and src/kernel/wasm-sandbox/worker.js.
Read tests/wasm-sandbox.test.js for existing test coverage.

Audit the WASM sandbox for:

1. MEMORY SAFETY: Can a WASM module allocate beyond its declared maximum?
   Can it access memory outside its linear memory? Does the validator
   correctly parse ALL valid memory section encodings (multi-byte LEB128)?

2. CPU EXHAUSTION: Can a module evade the timeout? What if it spends all
   time in a host call (Atomics.wait)? What about stack overflow vs infinite loop?

3. HOST FUNCTION ABUSE: Can a module call host functions it shouldn't have access to?
   Can it send oversized payloads through SharedArrayBuffer? What happens with
   malformed JSON in the IPC channel?

4. IMPORT VALIDATION: Can a module import functions from namespaces other than 'llmos'
   and 'env'? What if it imports a function that doesn't exist?

5. CONCURRENCY: What happens if two modules make host calls simultaneously?
   Is the SharedArrayBuffer layout safe against race conditions?

For each issue found, write a test case that demonstrates it and a fix.
Add tests to tests/wasm-sandbox.test.js.
```

### QC Prompt 6: Cross-Component Integration Audit

```
Read these files in order:
1. src/server.js — API endpoints
2. src/kernel/gateway.js — LLM routing and prompt handling
3. src/kernel/analyzer.js — static analysis
4. src/kernel/capabilities.js — capability enforcement
5. src/shell/sandbox.js — sandbox management
6. src/sdk/sdk.js — in-sandbox SDK

Trace the full request lifecycle: user types a prompt → LLM generates code →
analyzer scans it → capabilities are proposed → user approves → app launches
in sandbox → app calls SDK functions → kernel fulfills or denies.

For each handoff between components, check:
1. Is input validated at the boundary?
2. Can malformed data from one component crash another?
3. Are error cases handled (LLM returns garbage, analyzer throws, sandbox fails)?
4. Are there race conditions (two apps launched simultaneously, kill during launch)?

Produce a flow diagram with annotations showing where you found issues.
Write integration tests for any gaps you find.
```

### QC Prompt 7: Values Compliance Deep Scan

```
Read the 4 core values in CLAUDE.md (top of file).
Read scripts/values-check.js to understand what the automated checker covers.

Now read EVERY source file in src/ and scripts/. For each file, check:

VALUE 1 (Protect the user):
- Any network calls that could leak user data?
- Any hardcoded URLs that phone home?
- Any logging that includes user prompts or generated code?
- Any capability that's auto-granted without user approval?

VALUE 2 (Empower the user):
- Any artificial rate limits that aren't security-related?
- Any hardcoded model restrictions that prevent user choice?
- Any features gated behind specific providers?

VALUE 3 (Take a piece, leave a piece):
- Any code that would break if a component is removed?
- Any tight coupling that prevents standalone testing?

VALUE 4 (Nothing is perfect):
- Any TODO/FIXME/HACK comments that indicate known issues?
- Any error handling that silently swallows failures?

Output findings per file. For critical findings, submit fixes as a PR.
For minor findings, file GitHub issues.
```

---

## Low-Token Contributions (Quick Wins)

Have limited AI tokens? These focused tasks are small, self-contained, and valuable. Each takes 5–15 minutes.

### Security Test Vectors

```
Read tests/security/injection-vectors.json and tests/security/analyzer-vectors.json.
Add 5 NEW test vectors to each file. Focus on edge cases the existing vectors miss:
- Unicode homoglyph attacks (Cyrillic а instead of Latin a)
- Multi-line comment tricks (/* */ wrapping malicious code)
- CSS @import data exfiltration
- WebRTC-based fingerprinting
Follow the existing JSON format exactly. Each vector needs: input, shouldFlag (boolean), category, description.
```

### Example App

```
Read the examples/ directory. Look at calculator.html and todo.html for the pattern.
Build ONE new example app (pick one: unit converter, color picker, markdown previewer, habit tracker).
Use the same style: self-contained HTML, dark theme (#1a1a2e bg, #6c63ff accent),
capabilities comment on line 1, LLMOS.storage for persistence if needed.
Keep it under 120 lines.
```

### Analyzer Rule

```
Read src/kernel/analyzer.js. Understand the rule format.
Add ONE new detection rule for a pattern the analyzer currently misses.
Ideas: WebRTC access, SharedArrayBuffer, Blob URL creation, CSS expression(),
document.write, innerHTML with user input, importScripts in workers.
Add a matching test vector to tests/security/analyzer-vectors.json.
```

### Documentation Fix

```
Read README.md and CONTRIBUTING.md. Find anything unclear, outdated, or missing.
Fix it. Examples: broken links, unclear setup steps, missing prerequisites,
typos, better explanations for non-native English speakers.
```

---

## How to Contribute (Any Tool, Any AI, or No AI)

You don't need VS Code or Claude Code. This project welcomes contributions from any tool, any AI, or plain hand-written code. Pick whatever workflow suits you.

### Claude Code CLI (Terminal)

Works on any terminal — no IDE required.

```bash
# Fork, clone, and start working
gh repo fork DayZAnder/llm-os --clone && cd llm-os

# Claude Code reads CLAUDE.md automatically — it already knows the project
claude

# Or give it a task directly
claude "Read src/kernel/analyzer.js and add a detection rule for WebRTC data channels"

# Run tests when done
node tests/analyzer.test.js
node tests/storage.test.js
node tests/registry.test.js
```

Claude Code CLI reads `CLAUDE.md` on startup just like the VS Code extension — full project context, architecture, values, and coding style are all loaded automatically.

### Cursor / Windsurf / Cline / Aider

These editors and agents also read `CLAUDE.md` (or their equivalent context files). Clone the repo, open it, and the AI has full context.

```bash
gh repo fork DayZAnder/llm-os --clone && cd llm-os

# Cursor
cursor .

# Windsurf
windsurf .

# Aider (terminal-based)
aider --read CLAUDE.md
```

Pick a prompt from the list above and paste it into your AI assistant's chat.

### ChatGPT / Gemini / Grok / any other AI

These don't auto-read project files, so prepend this context block to any prompt:

```
PROJECT CONTEXT:
I'm contributing to LLM OS (https://github.com/DayZAnder/llm-os), an operating
system where every app is generated by AI from natural language prompts.

Core values (non-negotiable):
1. PROTECT THE USER FIRST — privacy, no telemetry, sandbox everything, user approves all capabilities
2. EMPOWER THE USER — no artificial limits, let them run what they want
3. TAKE A PIECE, LEAVE A PIECE — open source, contribute back, don't break the core
4. NOTHING IS PERFECT — ship working code, iterate, never violate core intent

Tech: Node.js 22+, vanilla JS (no React/Vue), ES modules, dark theme (#0d0d1a).
Zero runtime dependencies. Tests run with `node tests/*.test.js`.
Security: iframe sandboxes, capability-based access, regex static analyzer, prompt injection defense.

Key files:
- src/kernel/analyzer.js — static security analysis (35 regex rules)
- src/kernel/storage.js — per-app persistent storage (JSON files, 5MB quota)
- src/kernel/capabilities.js — capability-based access control
- src/kernel/gateway.js — LLM integration (pluggable: Ollama, Claude, OpenAI, and more)
- src/kernel/registry/store.js — app registry with search
- src/server.js — HTTP API server
- src/shell/index.html — desktop UI (vanilla JS, single file)
- src/sdk/sdk.js — SDK injected into sandboxed apps

Now, here's my task:
```

Then paste the specific task prompt. Copy the AI's output into the right files, test, and PR.

### Local LLMs (Ollama, llama.cpp, LM Studio)

If you run local models, you can use the project's own scripts as a starting point:

```bash
# Generate example apps with your local Ollama
node scripts/generate-apps.mjs

# Generate adversarial security test vectors
node scripts/generate-attack-vectors.mjs
```

These scripts use the Ollama API at `http://localhost:11434` by default (configurable via `OLLAMA_URL` env var). Any model that can generate HTML works — Qwen 2.5 14B, Llama 3, Mistral, etc.

### Contributing without AI

Human contributions are equally valuable — some of the most impactful work doesn't involve writing code at all:

- **Security audits** — Try to break the sandbox. Try prompt injection. File issues.
- **Threat modeling** — What attack vectors are we missing?
- **Design mockups** — UI/UX for the shell, capability dialogs, app launcher
- **Performance profiling** — Measure generation → sandbox → launch latency
- **Documentation** — Explain the architecture, write tutorials
- **Translations** — Localize the shell UI
- **Testing** — Run `node tests/*.test.js`, try edge cases, report failures

## Adding a Provider

The LLM gateway supports pluggable providers. To add a new one (e.g., Gemini, Mistral, a custom API):

**1. Create `src/kernel/providers/your-provider.js`:**

```javascript
export const provider = {
  name: 'your-provider',

  isAvailable(providerConfig) {
    return !!providerConfig.apiKey;
  },

  async checkHealth(providerConfig) {
    return !!providerConfig.apiKey;
  },

  async generate(messages, providerConfig, options = {}) {
    // messages: [{ role: 'system'|'user', content: string }]
    // options: { temperature, maxTokens }
    const res = await fetch('https://api.example.com/v1/generate', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${providerConfig.apiKey}`,
      },
      body: JSON.stringify({
        model: providerConfig.model,
        messages,
        temperature: options.temperature ?? 0.4,
        max_tokens: options.maxTokens ?? 4096,
      }),
    });
    if (!res.ok) throw new Error(`Provider error: ${res.status} ${await res.text()}`);
    const data = await res.json();
    return data.output; // Return the generated text string
  },
};
```

**2. Register it in `src/kernel/gateway.js`:**

```javascript
import { provider as yourProvider } from './providers/your-provider.js';
providers.set('your-provider', yourProvider);
```

**3. Add config in `src/kernel/config.js`:**

```javascript
providers: {
  // ... existing providers
  'your-provider': {
    apiKey: process.env.YOUR_PROVIDER_API_KEY || '',
    model: process.env.YOUR_PROVIDER_MODEL || 'default-model',
  },
},
```

**4. Add env vars to `.env.example`** and test with `node tests/gateway.test.js`.

If your provider uses the OpenAI-compatible `/v1/chat/completions` format (OpenRouter, Together, Groq, vLLM, LM Studio), you don't need a new provider at all — just set `OPENAI_BASE_URL` and `OPENAI_API_KEY`.

---

## Code Guidelines

- Vanilla JavaScript (ES modules, `type: "module"` in package.json)
- No classes where functions suffice
- No frameworks (React, Vue, Angular) in the shell or kernel
- Zero runtime dependencies unless absolutely necessary (currently: none)
- Tests welcome (vitest preferred, but any test runner works)
- Dark color scheme: `--bg-primary: #0d0d1a`, `--accent: #6c63ff`
- Every security decision should err on the side of denying access

## PR Checklist

Before submitting, verify:

- [ ] Does not add telemetry, analytics, or tracking of any kind
- [ ] Does not weaken sandbox isolation
- [ ] Does not bypass capability checks
- [ ] Does not add unnecessary dependencies
- [ ] Works standalone (can be tested independently)
- [ ] Follows the dark minimal visual style
- [ ] Includes tests for security-critical code
- [ ] References the relevant GitHub issue

## Communication

- **Issues:** Bug reports, feature proposals, security concerns
- **Discussions:** Architecture debates, open questions, ideas
- **PRs:** Code contributions (reference the issue number)
- **Security vulnerabilities:** File a private security advisory on GitHub

---

*This OS is built with AI, by AI, for humans. The next operating system won't ship apps — it will generate them. If that future interests you, clone the repo, pick your favorite tool, and start building.*
