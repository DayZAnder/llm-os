OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:14b
ANTHROPIC_API_KEY=
CLAUDE_MODEL=claude-sonnet-4-5-20250929
PORT=3000

# OpenAI-compatible (OpenAI, OpenRouter, Together, Groq, vLLM, LM Studio)
OPENAI_API_KEY=
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o

# Provider routing (optional â€” auto-detects if not set)
# Set PRIMARY_PROVIDER to force a specific provider for all requests
# Set FALLBACK_PROVIDER for automatic failover
PRIMARY_PROVIDER=
FALLBACK_PROVIDER=

# Docker configuration
DOCKER_ENABLED=true
DOCKER_HOST=
DOCKER_PORT_START=5100
DOCKER_PORT_END=5199
DOCKER_MAX_CONTAINERS=5

# Self-Improvement Scheduler
SCHEDULER_ENABLED=false
SCHEDULER_DEFER_MINUTES=5
SCHEDULER_PROVIDER=ollama
SCHEDULER_DAILY_BUDGET=30
SCHEDULER_MAX_REGISTRY=500

# Claude Code Agent (requires ANTHROPIC_API_KEY + claude CLI installed)
# Spawns Claude Code to debug, fix, and improve the OS codebase
# Queue tasks via POST /api/claude-tasks or let other tasks auto-queue
CLAUDE_AGENT_ENABLED=false
